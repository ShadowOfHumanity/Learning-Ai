# **Machine Learning** 


### What **is** Machine learning?
#### **Core Idea**
> Machine Learning = **finding parameters that minimize errors**

Every ML model:

**1.** Takes input data
**2.** Applies math with parameters (weights)
**3.** Produces output
**4.** Measures how wrong it is (loss)
**5.** Adjusts Parameters to reduce errors

Neural networks, trees, transformers, ... all follow these rule/loop

----

#### **Key Terms**
- **Model**: A function with parameters
- **Parameters**: Numbers the model learns
- **Loss function**: How wrong the model is
- **Training**: Minimizing loss
- **Inference**: Using the trained model

----

> Why is **"Training"** just optimization?

my words:
Training is just optimization because you adjust its weights, the parameters so that the information needed and the loss would be more accurate, and minamized.